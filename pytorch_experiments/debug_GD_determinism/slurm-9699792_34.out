/home/brando90/home_simulation_research/overparametrized_experiments/pytorch_experiments
SLURM_ARRAY_TASK_ID =  34
SLURM_JOBID =  9699829

--Degree_mdl=6 
--degrees=[3, 4, 5, 6, 7, 8] 
--SLURM_ARRAY_TASK_ID=34 

reg_lambda =  0
nb_iter =  800000
N_train=7, N_test=200
--->training SP mdl
nb =  800000
reg_lambda =  0
reg_type =  
reg_lambda=0
-------------
i = 0, current_train_loss = [ 0.42564547]
W.data = 

Columns 0 to 5 
-2.7992e-17  8.2479e-03  8.2479e-03  7.7896e-03  7.3314e-03  6.7841e-03

Columns 6 to 6 
 6.1477e-03
[torch.FloatTensor of size 1x7]

W.grad.data = 

Columns 0 to 5 
 2.7992e-16 -8.2479e-02 -8.2479e-02 -7.7896e-02 -7.3314e-02 -6.7841e-02

Columns 6 to 6 
-6.1477e-02
[torch.FloatTensor of size 1x7]

-------------
i = 80000, current_train_loss = [ 0.38830802]
W.data = 
-0.2229  1.8812 -4.4255 -1.7785  7.3262  5.8397 -8.4941
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0615 -1.4745  3.0818  3.7534 -6.6790 -6.6513  7.9337
[torch.FloatTensor of size 1x7]

-------------
i = 160000, current_train_loss = [ 0.3776879]
W.data = 
 -0.2565   2.6056  -5.4574  -5.3105  11.5311  10.7552 -13.7551
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0197 -0.4700 -0.1061  4.9189 -4.1522 -5.7468  5.5230
[torch.FloatTensor of size 1x7]

-------------
i = 240000, current_train_loss = [ 0.37011281]
W.data = 
 -0.2710   2.7709  -4.7048  -9.4870  14.3088  15.1469 -17.6586
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0039  0.0063 -1.6026  5.4241 -2.9619 -5.2930  4.3901
[torch.FloatTensor of size 1x7]

-------------
i = 320000, current_train_loss = [ 0.36330244]
W.data = 
 -0.2764   2.6755  -3.1278 -13.9432  16.4161  19.2721 -20.9148
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0140  0.2281 -2.2557  5.6724 -2.3638 -5.0394  3.8447
[torch.FloatTensor of size 1x7]

-------------
i = 400000, current_train_loss = [ 0.35675451]
W.data = 
 -0.2776   2.4577  -1.1703 -18.5056  18.1871  23.2593 -23.8514
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0118  0.3193 -2.5501  5.7482 -2.0960 -4.9242  3.5425
[torch.FloatTensor of size 1x7]

-------------
i = 480000, current_train_loss = [ 0.3503677]
W.data = 
 -0.2769   2.1883   0.9404 -23.0833  19.7971  27.1595 -26.6274
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0016  0.3635 -2.7025  5.7318 -1.9812 -4.8652  3.3652
[torch.FloatTensor of size 1x7]

-------------
i = 560000, current_train_loss = [ 0.34410283]
W.data = 
 -0.2752   1.8908   3.1307 -27.6609  21.3230  30.9916 -29.3035
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0022  0.3707 -2.7537  5.7078 -1.8943 -4.7714  3.3297
[torch.FloatTensor of size 1x7]

-------------
i = 640000, current_train_loss = [ 0.33795017]
W.data = 
 -0.2732   1.5835   5.3460 -32.2362  22.8489  34.7420 -31.9157
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0054  0.3939 -2.7764  5.6352 -1.8907 -4.7564  3.2429
[torch.FloatTensor of size 1x7]

-------------
i = 720000, current_train_loss = [ 0.33190343]
W.data = 
 -0.2708   1.2676   7.5836 -36.8091  24.3748  38.4157 -34.4671
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0069  0.3895 -2.7860  5.5477 -1.8948 -4.7119  3.2372
[torch.FloatTensor of size 1x7]

--- 393.0971529483795 seconds ---
--- 6.551619215806325 minutes ---
--- 0.10919365359677209 hours ---

plotting={'save_bulk_experiment': True, 'plotting': False}
lb_test=
