/home/slurm/slurmd/job9699842/slurm_script:268: RankWarning: Polyfit may be poorly conditioned
  c_pinv = np.polyfit( X_train.reshape((N_train,)) , Y_train.reshape((N_train,)) , Degree_mdl )[::-1]
/home/brando90/home_simulation_research/overparametrized_experiments/pytorch_experiments
SLURM_ARRAY_TASK_ID =  47
SLURM_JOBID =  9699842

--Degree_mdl=7 
--degrees=[3, 4, 5, 6, 7, 8] 
--SLURM_ARRAY_TASK_ID=47 

reg_lambda =  0
nb_iter =  800000
N_train=7, N_test=200
--->training SP mdl
nb =  800000
reg_lambda =  0
reg_type =  
reg_lambda=0
-------------
i = 0, current_train_loss = [ 0.42543319]
W.data = 

Columns 0 to 5 
-2.7992e-17  8.2479e-03  8.2479e-03  7.7896e-03  7.3314e-03  6.7841e-03

Columns 6 to 7 
 6.1477e-03  5.4685e-03
[torch.FloatTensor of size 1x8]

W.grad.data = 

Columns 0 to 5 
 2.7992e-16 -8.2479e-02 -8.2479e-02 -7.7896e-02 -7.3314e-02 -6.7841e-02

Columns 6 to 7 
-6.1477e-02 -5.4685e-02
[torch.FloatTensor of size 1x8]

-------------
i = 80000, current_train_loss = [ 0.35714465]
W.data = 
 -0.2700   2.8360  -5.4458  -5.2142   6.4380  10.7190   3.5493 -12.5228
[torch.FloatTensor of size 1x8]

W.grad.data = 
1.00000e-03 *
  0.0087 -0.1381  0.0745  0.7871 -0.3201 -0.9669 -0.4650  1.0159
[torch.FloatTensor of size 1x8]

-------------
i = 160000, current_train_loss = [ 0.33891523]
W.data = 
 -0.3033   3.1418  -3.8770 -11.7177   7.5046  17.1711   7.1858 -19.0293
[torch.FloatTensor of size 1x8]

W.grad.data = 
1.00000e-04 *
  0.0198  0.2594 -3.6845  8.2590 -0.1451 -7.0288 -4.4877  6.7775
[torch.FloatTensor of size 1x8]

-------------
i = 240000, current_train_loss = [ 0.32382476]
W.data = 
 -0.3071   2.7279  -0.3855 -18.3185   7.2264  22.4083  10.7123 -23.9925
[torch.FloatTensor of size 1x8]

W.grad.data = 
1.00000e-04 *
 -0.0024  0.6650 -4.7707  8.2355  0.6701 -6.1994 -4.3411  5.8098
[torch.FloatTensor of size 1x8]

-------------
i = 320000, current_train_loss = [ 0.30958438]
W.data = 
 -0.3031   2.1333   3.5492 -24.8398   6.6169  27.2240  14.1618 -28.4736
[torch.FloatTensor of size 1x8]

W.grad.data = 
1.00000e-04 *
 -0.0034  0.7767 -4.9500  8.1052  0.8730 -5.8828 -4.2385  5.4415
[torch.FloatTensor of size 1x8]

-------------
i = 400000, current_train_loss = [ 0.29600629]
W.data = 
 -0.2972   1.5029   7.5290 -31.2269   5.9256  31.8657  17.5192 -32.7516
[torch.FloatTensor of size 1x8]

W.grad.data = 
1.00000e-04 *
 -0.0025  0.7773 -4.9267  7.9108  0.8669 -5.7624 -4.2182  5.1549
[torch.FloatTensor of size 1x8]

-------------
i = 480000, current_train_loss = [ 0.28301775]
W.data = 
 -0.2911   0.8747  11.4568 -37.4775   5.2057  36.4120  20.7996 -36.9152
[torch.FloatTensor of size 1x8]

W.grad.data = 
1.00000e-04 *
 -0.0065  0.7951 -4.8453  7.7557  0.9196 -5.5268 -4.0061  5.1444
[torch.FloatTensor of size 1x8]

-------------
i = 560000, current_train_loss = [ 0.27073804]
W.data = 
 -0.2844   0.2450  15.3280 -43.5769   4.5468  40.7084  23.9977 -40.9009
[torch.FloatTensor of size 1x8]

W.grad.data = 
1.00000e-04 *
 -0.0176  0.7668 -4.7940  7.4380  0.7538 -5.4867 -3.9165  5.1089
[torch.FloatTensor of size 1x8]

-------------
i = 640000, current_train_loss = [ 0.2589789]
W.data = 
 -0.2783  -0.3511  19.0494 -49.5182   3.9116  44.9808  27.1357 -44.8682
[torch.FloatTensor of size 1x8]

W.grad.data = 
1.00000e-04 *
 -0.0182  0.7235 -4.5688  7.4253  0.8419 -5.3445 -3.9139  4.7938
[torch.FloatTensor of size 1x8]

-------------
i = 720000, current_train_loss = [ 0.24768926]
W.data = 
 -0.2727  -0.9364  22.7073 -55.3262   3.2054  49.2413  30.1945 -48.7529
[torch.FloatTensor of size 1x8]

W.grad.data = 
1.00000e-04 *
  0.0095  0.7472 -4.5212  7.2449  0.8593 -5.1484 -3.7304  4.7786
[torch.FloatTensor of size 1x8]

--- 616.4538969993591 seconds ---
--- 10.274231616655985 minutes ---
--- 0.1712371936109331 hours ---

plotting={'save_bulk_experiment': True, 'plotting': False}
lb_test=
