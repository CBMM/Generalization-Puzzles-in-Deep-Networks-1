/home/brando90/home_simulation_research/overparametrized_experiments/pytorch_experiments
SLURM_ARRAY_TASK_ID =  38
SLURM_JOBID =  9699833

--Degree_mdl=6 
--degrees=[3, 4, 5, 6, 7, 8] 
--SLURM_ARRAY_TASK_ID=38 

reg_lambda =  0
nb_iter =  800000
N_train=7, N_test=200
--->training SP mdl
nb =  800000
reg_lambda =  0
reg_type =  
reg_lambda=0
-------------
i = 0, current_train_loss = [ 0.42564547]
W.data = 
1.00000e-03 *
  0.0000  8.2479  8.2479  7.7896  7.3314  6.7841  6.1477
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-02 *
  0.0000 -8.2479 -8.2479 -7.7896 -7.3314 -6.7841 -6.1477
[torch.FloatTensor of size 1x7]

-------------
i = 80000, current_train_loss = [ 0.38830775]
W.data = 
-0.2229  1.8812 -4.4255 -1.7785  7.3262  5.8397 -8.4941
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0629 -1.4743  3.0818  3.7532 -6.6792 -6.6515  7.9335
[torch.FloatTensor of size 1x7]

-------------
i = 160000, current_train_loss = [ 0.37768826]
W.data = 
 -0.2565   2.6056  -5.4574  -5.3105  11.5311  10.7552 -13.7551
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0319 -0.4628 -0.1010  4.9227 -4.1492 -5.7444  5.5250
[torch.FloatTensor of size 1x7]

-------------
i = 240000, current_train_loss = [ 0.37011296]
W.data = 
 -0.2710   2.7709  -4.7048  -9.4870  14.3089  15.1469 -17.6586
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0051  0.0051 -1.6043  5.4218 -2.9648 -5.2963  4.3865
[torch.FloatTensor of size 1x7]

-------------
i = 320000, current_train_loss = [ 0.36330241]
W.data = 
 -0.2764   2.6754  -3.1278 -13.9432  16.4162  19.2720 -20.9148
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0146  0.2269 -2.2582  5.6684 -2.3690 -5.0456  3.8377
[torch.FloatTensor of size 1x7]

-------------
i = 400000, current_train_loss = [ 0.35675493]
W.data = 
 -0.2776   2.4577  -1.1703 -18.5057  18.1872  23.2592 -23.8514
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0021  0.3071 -2.5616  5.7370 -2.1071 -4.9352  3.5316
[torch.FloatTensor of size 1x7]

-------------
i = 480000, current_train_loss = [ 0.35036784]
W.data = 
 -0.2769   2.1883   0.9403 -23.0833  19.7973  27.1593 -26.6273
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0057  0.3727 -2.6930  5.7419 -1.9709 -4.8547  3.3758
[torch.FloatTensor of size 1x7]

-------------
i = 560000, current_train_loss = [ 0.34410277]
W.data = 
 -0.2752   1.8908   3.1307 -27.6610  21.3232  30.9915 -29.3035
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0133  0.3664 -2.7561  5.7065 -1.8950 -4.7719  3.3295
[torch.FloatTensor of size 1x7]

-------------
i = 640000, current_train_loss = [ 0.33794931]
W.data = 
 -0.2732   1.5835   5.3462 -32.2366  22.8491  34.7420 -31.9156
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0104  0.3959 -2.7786  5.6317 -1.8946 -4.7600  3.2397
[torch.FloatTensor of size 1x7]

-------------
i = 720000, current_train_loss = [ 0.3319065]
W.data = 
 -0.2707   1.2665   7.5868 -36.8107  24.3749  38.4095 -34.4618
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0213  0.4089 -2.7703  5.5570 -1.8862 -4.7001  3.2542
[torch.FloatTensor of size 1x7]

--- 386.62493872642517 seconds ---
--- 6.443748978773753 minutes ---
--- 0.10739581631289588 hours ---

plotting={'save_bulk_experiment': True, 'plotting': False}
lb_test=
