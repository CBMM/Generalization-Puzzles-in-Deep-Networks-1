/home/brando90/home_simulation_research/overparametrized_experiments/pytorch_experiments
SLURM_ARRAY_TASK_ID =  40
SLURM_JOBID =  9699835

--Degree_mdl=6 
--degrees=[3, 4, 5, 6, 7, 8] 
--SLURM_ARRAY_TASK_ID=40 

reg_lambda =  0
nb_iter =  800000
N_train=7, N_test=200
--->training SP mdl
nb =  800000
reg_lambda =  0
reg_type =  
reg_lambda=0
-------------
i = 0, current_train_loss = [ 0.42564547]
W.data = 
1.00000e-03 *
  0.0000  8.2479  8.2479  7.7896  7.3314  6.7841  6.1477
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-02 *
  0.0000 -8.2479 -8.2479 -7.7896 -7.3314 -6.7841 -6.1477
[torch.FloatTensor of size 1x7]

-------------
i = 80000, current_train_loss = [ 0.38830787]
W.data = 
-0.2229  1.8812 -4.4255 -1.7785  7.3261  5.8397 -8.4941
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0627 -1.4748  3.0814  3.7529 -6.6794 -6.6516  7.9333
[torch.FloatTensor of size 1x7]

-------------
i = 160000, current_train_loss = [ 0.37768802]
W.data = 
 -0.2565   2.6056  -5.4574  -5.3105  11.5311  10.7552 -13.7551
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0370 -0.4576 -0.0955  4.9284 -4.1436 -5.7388  5.5305
[torch.FloatTensor of size 1x7]

-------------
i = 240000, current_train_loss = [ 0.37011296]
W.data = 
 -0.2710   2.7709  -4.7048  -9.4870  14.3088  15.1470 -17.6586
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0170  0.0158 -1.5952  5.4300 -2.9573 -5.2893  4.3931
[torch.FloatTensor of size 1x7]

-------------
i = 320000, current_train_loss = [ 0.36330235]
W.data = 
 -0.2764   2.6754  -3.1278 -13.9432  16.4162  19.2720 -20.9147
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0046  0.2152 -2.2694  5.6575 -2.3800 -5.0565  3.8267
[torch.FloatTensor of size 1x7]

-------------
i = 400000, current_train_loss = [ 0.3567546]
W.data = 
 -0.2776   2.4577  -1.1703 -18.5057  18.1871  23.2592 -23.8514
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0021  0.3098 -2.5598  5.7381 -2.1064 -4.9347  3.5318
[torch.FloatTensor of size 1x7]

-------------
i = 480000, current_train_loss = [ 0.35036764]
W.data = 
 -0.2769   2.1882   0.9404 -23.0833  19.7971  27.1595 -26.6273
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0004  0.3623 -2.7043  5.7299 -1.9831 -4.8670  3.3636
[torch.FloatTensor of size 1x7]

-------------
i = 560000, current_train_loss = [ 0.34410295]
W.data = 
 -0.2752   1.8908   3.1308 -27.6609  21.3229  30.9917 -29.3035
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0066  0.3698 -2.7540  5.7078 -1.8943 -4.7714  3.3297
[torch.FloatTensor of size 1x7]

-------------
i = 640000, current_train_loss = [ 0.3379491]
W.data = 
 -0.2732   1.5834   5.3463 -32.2365  22.8488  34.7422 -31.9157
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0145  0.3991 -2.7739  5.6372 -1.8883 -4.7530  3.2473
[torch.FloatTensor of size 1x7]

-------------
i = 720000, current_train_loss = [ 0.3319068]
W.data = 
 -0.2707   1.2665   7.5869 -36.8106  24.3747  38.4096 -34.4618
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0134  0.4046 -2.7738  5.5539 -1.8888 -4.7023  3.2523
[torch.FloatTensor of size 1x7]

--- 387.07886385917664 seconds ---
--- 6.451314397652944 minutes ---
--- 0.10752190662754907 hours ---

plotting={'save_bulk_experiment': True, 'plotting': False}
lb_test=
