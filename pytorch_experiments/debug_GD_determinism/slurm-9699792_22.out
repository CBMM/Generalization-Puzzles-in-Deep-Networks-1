/home/brando90/home_simulation_research/overparametrized_experiments/pytorch_experiments
SLURM_ARRAY_TASK_ID =  22
SLURM_JOBID =  9699817

--Degree_mdl=5 
--degrees=[3, 4, 5, 6, 7, 8] 
--SLURM_ARRAY_TASK_ID=22 

reg_lambda =  0
nb_iter =  800000
N_train=7, N_test=200
--->training SP mdl
nb =  800000
reg_lambda =  0
reg_type =  
reg_lambda=0
-------------
i = 0, current_train_loss = [ 0.42593381]
W.data = 
-2.7992e-17  8.2479e-03  8.2479e-03  7.7896e-03  7.3314e-03  6.7841e-03
[torch.FloatTensor of size 1x6]

W.grad.data = 
 2.7992e-16 -8.2479e-02 -8.2479e-02 -7.7896e-02 -7.3314e-02 -6.7841e-02
[torch.FloatTensor of size 1x6]

-------------
i = 80000, current_train_loss = [ 0.4082202]
W.data = 
-0.1911  0.8607 -1.9736  0.2909  4.6952 -3.5192
[torch.FloatTensor of size 1x6]

W.grad.data = 
1.00000e-04 *
  0.0218 -0.6992  2.1971  0.2819 -5.4702  3.7023
[torch.FloatTensor of size 1x6]

-------------
i = 160000, current_train_loss = [ 0.40492573]
W.data = 
-0.2058  1.3203 -3.3413 -0.2360  8.7952 -6.1767
[torch.FloatTensor of size 1x6]

W.grad.data = 
1.00000e-04 *
  0.0165 -0.4618  1.2767  0.9926 -4.8155  2.9823
[torch.FloatTensor of size 1x6]

-------------
i = 240000, current_train_loss = [ 0.40245447]
W.data = 
 -0.2161   1.6205  -4.0874  -1.2492  12.4382  -8.3555
[torch.FloatTensor of size 1x6]

W.grad.data = 
1.00000e-04 *
  0.0077 -0.2950  0.6202  1.5002 -4.3395  2.4806
[torch.FloatTensor of size 1x6]

-------------
i = 320000, current_train_loss = [ 0.40040386]
W.data = 
 -0.2234   1.8070  -4.3908  -2.6084  15.7558 -10.1935
[torch.FloatTensor of size 1x6]

W.grad.data = 
1.00000e-04 *
  0.0046 -0.1791  0.1634  1.8768 -3.9793  2.1434
[torch.FloatTensor of size 1x6]

-------------
i = 400000, current_train_loss = [ 0.39856568]
W.data = 
 -0.2284   1.9131  -4.3787  -4.2179  18.8467 -11.7909
[torch.FloatTensor of size 1x6]

W.grad.data = 
1.00000e-04 *
  0.0069 -0.0819 -0.1679  2.1377 -3.7203  1.9093
[torch.FloatTensor of size 1x6]

-------------
i = 480000, current_train_loss = [ 0.39684466]
W.data = 
 -0.2318   1.9609  -4.1415  -5.9984  21.7631 -13.2104
[torch.FloatTensor of size 1x6]

W.grad.data = 
1.00000e-04 *
  0.0023 -0.0285 -0.4076  2.3215 -3.5314  1.7478
[torch.FloatTensor of size 1x6]

-------------
i = 560000, current_train_loss = [ 0.39518982]
W.data = 
 -0.2341   1.9669  -3.7447  -7.8949  24.5483 -14.5013
[torch.FloatTensor of size 1x6]

W.grad.data = 
1.00000e-04 *
  0.0009  0.0121 -0.5692  2.4342 -3.4373  1.5690
[torch.FloatTensor of size 1x6]

-------------
i = 640000, current_train_loss = [ 0.39354876]
W.data = 
 -0.2356   1.9470  -3.2418  -9.8914  27.2864 -15.7255
[torch.FloatTensor of size 1x6]

W.grad.data = 
1.00000e-04 *
 -0.0037  0.0344 -0.6969  2.5251 -3.3410  1.4728
[torch.FloatTensor of size 1x6]

-------------
i = 720000, current_train_loss = [ 0.3919546]
W.data = 
 -0.2365   1.9005  -2.6409 -11.9388  29.9008 -16.8469
[torch.FloatTensor of size 1x6]

W.grad.data = 
1.00000e-04 *
  0.0009  0.0664 -0.7770  2.5793 -3.2716  1.4279
[torch.FloatTensor of size 1x6]

--- 390.64996671676636 seconds ---
--- 6.510832778612772 minutes ---
--- 0.10851387964354621 hours ---

plotting={'save_bulk_experiment': True, 'plotting': False}
lb_test=
