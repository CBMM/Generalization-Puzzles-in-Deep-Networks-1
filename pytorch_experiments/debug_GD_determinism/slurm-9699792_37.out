/home/brando90/home_simulation_research/overparametrized_experiments/pytorch_experiments
SLURM_ARRAY_TASK_ID =  37
SLURM_JOBID =  9699832

--Degree_mdl=6 
--degrees=[3, 4, 5, 6, 7, 8] 
--SLURM_ARRAY_TASK_ID=37 

reg_lambda =  0
nb_iter =  800000
N_train=7, N_test=200
--->training SP mdl
nb =  800000
reg_lambda =  0
reg_type =  
reg_lambda=0
-------------
i = 0, current_train_loss = [ 0.42564547]
W.data = 
1.00000e-03 *
  0.0000  8.2479  8.2479  7.7896  7.3314  6.7841  6.1477
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-02 *
  0.0000 -8.2479 -8.2479 -7.7896 -7.3314 -6.7841 -6.1477
[torch.FloatTensor of size 1x7]

-------------
i = 80000, current_train_loss = [ 0.38830799]
W.data = 
-0.2229  1.8812 -4.4255 -1.7785  7.3262  5.8397 -8.4941
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0620 -1.4746  3.0815  3.7529 -6.6794 -6.6516  7.9334
[torch.FloatTensor of size 1x7]

-------------
i = 160000, current_train_loss = [ 0.37768784]
W.data = 
 -0.2565   2.6056  -5.4574  -5.3105  11.5311  10.7552 -13.7551
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0176 -0.4741 -0.1108  4.9139 -4.1574 -5.7521  5.5176
[torch.FloatTensor of size 1x7]

-------------
i = 240000, current_train_loss = [ 0.3701131]
W.data = 
 -0.2710   2.7709  -4.7048  -9.4870  14.3089  15.1469 -17.6587
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0124  0.0132 -1.5966  5.4291 -2.9578 -5.2896  4.3929
[torch.FloatTensor of size 1x7]

-------------
i = 320000, current_train_loss = [ 0.36330253]
W.data = 
 -0.2764   2.6755  -3.1279 -13.9432  16.4162  19.2720 -20.9148
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0028  0.2110 -2.2735  5.6540 -2.3828 -5.0588  3.8249
[torch.FloatTensor of size 1x7]

-------------
i = 400000, current_train_loss = [ 0.35675466]
W.data = 
 -0.2776   2.4577  -1.1703 -18.5056  18.1871  23.2592 -23.8514
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0095  0.3194 -2.5497  5.7486 -2.0957 -4.9239  3.5427
[torch.FloatTensor of size 1x7]

-------------
i = 480000, current_train_loss = [ 0.35036784]
W.data = 
 -0.2769   2.1883   0.9404 -23.0833  19.7971  27.1594 -26.6273
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0030  0.3600 -2.7058  5.7289 -1.9838 -4.8674  3.3633
[torch.FloatTensor of size 1x7]

-------------
i = 560000, current_train_loss = [ 0.34410283]
W.data = 
 -0.2752   1.8908   3.1307 -27.6609  21.3230  30.9916 -29.3035
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0083  0.3850 -2.7394  5.7218 -1.8808 -4.7584  3.3424
[torch.FloatTensor of size 1x7]

-------------
i = 640000, current_train_loss = [ 0.33794963]
W.data = 
 -0.2732   1.5835   5.3462 -32.2365  22.8489  34.7421 -31.9156
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0023  0.3855 -2.7874  5.6238 -1.9014 -4.7658  3.2348
[torch.FloatTensor of size 1x7]

-------------
i = 720000, current_train_loss = [ 0.33190665]
W.data = 
 -0.2707   1.2666   7.5868 -36.8105  24.3748  38.4095 -34.4618
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0120  0.4004 -2.7797  5.5470 -1.8965 -4.7106  3.2435
[torch.FloatTensor of size 1x7]

--- 385.50555658340454 seconds ---
--- 6.425092609723409 minutes ---
--- 0.10708487682872349 hours ---

plotting={'save_bulk_experiment': True, 'plotting': False}
lb_test=
