/home/brando90/home_simulation_research/overparametrized_experiments/pytorch_experiments
SLURM_ARRAY_TASK_ID =  15
SLURM_JOBID =  9699810

--Degree_mdl=4 
--degrees=[3, 4, 5, 6, 7, 8] 
--SLURM_ARRAY_TASK_ID=15 

reg_lambda =  0
nb_iter =  800000
N_train=7, N_test=200
--->training SP mdl
nb =  800000
reg_lambda =  0
reg_type =  
reg_lambda=0
-------------
i = 0, current_train_loss = [ 0.42630515]
W.data = 
-2.7992e-17  8.2479e-03  8.2479e-03  7.7896e-03  7.3314e-03
[torch.FloatTensor of size 1x5]

W.grad.data = 
 2.7992e-16 -8.2479e-02 -8.2479e-02 -7.7896e-02 -7.3314e-02
[torch.FloatTensor of size 1x5]

-------------
i = 80000, current_train_loss = [ 0.41326532]
W.data = 
-0.1855  0.3679  0.0164 -0.0258  0.0127
[torch.FloatTensor of size 1x5]

W.grad.data = 
1.00000e-07 *
  0.2980 -1.3674  1.9660 -2.8899  1.2967
[torch.FloatTensor of size 1x5]

-------------
i = 160000, current_train_loss = [ 0.41326532]
W.data = 
-0.1855  0.3682  0.0150 -0.0236  0.0116
[torch.FloatTensor of size 1x5]

W.grad.data = 
1.00000e-07 *
  0.1490 -1.1567  1.7306 -2.5696  1.3854
[torch.FloatTensor of size 1x5]

-------------
i = 240000, current_train_loss = [ 0.41326532]
W.data = 
-0.1855  0.3684  0.0137 -0.0216  0.0106
[torch.FloatTensor of size 1x5]

W.grad.data = 
1.00000e-07 *
  0.0000 -1.3178  1.4672 -2.4539  1.1813
[torch.FloatTensor of size 1x5]

-------------
i = 320000, current_train_loss = [ 0.41326532]
W.data = 
-0.1855  0.3687  0.0125 -0.0197  0.0097
[torch.FloatTensor of size 1x5]

W.grad.data = 
1.00000e-07 *
  0.1490 -1.4231  1.3435 -2.1760  1.1259
[torch.FloatTensor of size 1x5]

-------------
i = 400000, current_train_loss = [ 0.41326532]
W.data = 
-0.1855  0.3689  0.0115 -0.0180  0.0088
[torch.FloatTensor of size 1x5]

W.grad.data = 
1.00000e-07 *
  0.2980 -1.0401  1.4161 -1.9368  1.0557
[torch.FloatTensor of size 1x5]

-------------
i = 480000, current_train_loss = [ 0.41326532]
W.data = 
-0.1855  0.3691  0.0105 -0.0165  0.0081
[torch.FloatTensor of size 1x5]

W.grad.data = 
1.00000e-07 *
  0.2980 -1.1191  1.3286 -1.7209  1.0251
[torch.FloatTensor of size 1x5]

-------------
i = 560000, current_train_loss = [ 0.41326532]
W.data = 
-0.1855  0.3692  0.0096 -0.0151  0.0074
[torch.FloatTensor of size 1x5]

W.grad.data = 
1.00000e-07 *
 -0.2608 -1.4374  1.2009 -1.6333  0.7365
[torch.FloatTensor of size 1x5]

-------------
i = 640000, current_train_loss = [ 0.41326532]
W.data = 
-0.1855  0.3694  0.0088 -0.0138  0.0068
[torch.FloatTensor of size 1x5]

W.grad.data = 
1.00000e-07 *
  0.2980 -1.2809  1.1263 -1.4138  0.8945
[torch.FloatTensor of size 1x5]

-------------
i = 720000, current_train_loss = [ 0.41326532]
W.data = 
-0.1855  0.3695  0.0081 -0.0127  0.0062
[torch.FloatTensor of size 1x5]

W.grad.data = 
1.00000e-07 *
 -0.1863 -1.2884  0.7787 -1.5919  0.5158
[torch.FloatTensor of size 1x5]

--- 416.2979464530945 seconds ---
--- 6.9382991075515745 minutes ---
--- 0.11563831845919291 hours ---

plotting={'save_bulk_experiment': True, 'plotting': False}
lb_test=
