/home/brando90/home_simulation_research/overparametrized_experiments/pytorch_experiments
SLURM_ARRAY_TASK_ID =  35
SLURM_JOBID =  9699830

--Degree_mdl=6 
--degrees=[3, 4, 5, 6, 7, 8] 
--SLURM_ARRAY_TASK_ID=35 

reg_lambda =  0
nb_iter =  800000
N_train=7, N_test=200
--->training SP mdl
nb =  800000
reg_lambda =  0
reg_type =  
reg_lambda=0
-------------
i = 0, current_train_loss = [ 0.42564547]
W.data = 

Columns 0 to 5 
-1.3996e-17  8.2479e-03  8.2479e-03  7.7896e-03  7.3314e-03  6.7841e-03

Columns 6 to 6 
 6.1477e-03
[torch.FloatTensor of size 1x7]

W.grad.data = 

Columns 0 to 5 
 1.3996e-16 -8.2479e-02 -8.2479e-02 -7.7896e-02 -7.3314e-02 -6.7841e-02

Columns 6 to 6 
-6.1477e-02
[torch.FloatTensor of size 1x7]

-------------
i = 80000, current_train_loss = [ 0.38830787]
W.data = 
-0.2229  1.8812 -4.4255 -1.7785  7.3262  5.8397 -8.4941
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0627 -1.4748  3.0808  3.7519 -6.6807 -6.6532  7.9316
[torch.FloatTensor of size 1x7]

-------------
i = 160000, current_train_loss = [ 0.37768811]
W.data = 
 -0.2565   2.6056  -5.4574  -5.3105  11.5311  10.7551 -13.7551
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0231 -0.4688 -0.1056  4.9191 -4.1521 -5.7468  5.5231
[torch.FloatTensor of size 1x7]

-------------
i = 240000, current_train_loss = [ 0.37011293]
W.data = 
 -0.2710   2.7709  -4.7048  -9.4870  14.3088  15.1470 -17.6587
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0097  0.0095 -1.6006  5.4249 -2.9623 -5.2941  4.3883
[torch.FloatTensor of size 1x7]

-------------
i = 320000, current_train_loss = [ 0.36330217]
W.data = 
 -0.2764   2.6755  -3.1278 -13.9433  16.4162  19.2721 -20.9148
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0131  0.1994 -2.2849  5.6427 -2.3939 -5.0699  3.8138
[torch.FloatTensor of size 1x7]

-------------
i = 400000, current_train_loss = [ 0.35675463]
W.data = 
 -0.2776   2.4577  -1.1703 -18.5057  18.1872  23.2592 -23.8514
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0122  0.3005 -2.5667  5.7329 -2.1104 -4.9378  3.5295
[torch.FloatTensor of size 1x7]

-------------
i = 480000, current_train_loss = [ 0.3503679]
W.data = 
 -0.2769   2.1883   0.9404 -23.0834  19.7972  27.1594 -26.6274
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0092  0.3556 -2.7096  5.7257 -1.9863 -4.8695  3.3615
[torch.FloatTensor of size 1x7]

-------------
i = 560000, current_train_loss = [ 0.34410292]
W.data = 
 -0.2752   1.8908   3.1307 -27.6610  21.3232  30.9915 -29.3035
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0072  0.3834 -2.7405  5.7209 -1.8813 -4.7587  3.3422
[torch.FloatTensor of size 1x7]

-------------
i = 640000, current_train_loss = [ 0.3379494]
W.data = 
 -0.2732   1.5835   5.3463 -32.2366  22.8490  34.7421 -31.9156
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0024  0.3863 -2.7862  5.6254 -1.8998 -4.7643  3.2361
[torch.FloatTensor of size 1x7]

-------------
i = 720000, current_train_loss = [ 0.33190671]
W.data = 
 -0.2707   1.2665   7.5869 -36.8107  24.3749  38.4094 -34.4617
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0215  0.3759 -2.8001  5.5287 -1.9133 -4.7263  3.2287
[torch.FloatTensor of size 1x7]

--- 391.06079483032227 seconds ---
--- 6.5176799138387045 minutes ---
--- 0.10862799856397841 hours ---

plotting={'save_bulk_experiment': True, 'plotting': False}
lb_test=
