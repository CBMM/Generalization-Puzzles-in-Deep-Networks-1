/home/brando90/home_simulation_research/overparametrized_experiments/pytorch_experiments
SLURM_ARRAY_TASK_ID =  39
SLURM_JOBID =  9700048

--Degree_mdl=6 
--degrees=[3, 4, 5, 6, 7, 8] 
--SLURM_ARRAY_TASK_ID=39 

reg_lambda =  0
nb_iter =  200
N_train=7, N_test=200
--->training SP mdl
nb =  200
reg_lambda =  0
reg_type =  
mdl_sgd[0].weight=Parameter containing:
    0     0     0     0     0     0     0
[torch.FloatTensor of size 1x7]

reg_lambda=0
-------------
i = 0, current_train_loss = [ 0.42564547]
W.data = 
1.00000e-03 *
  0.0000  8.2479  8.2479  7.7896  7.3314  6.7841  6.1477
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-02 *
  0.0000 -8.2479 -8.2479 -7.7896 -7.3314 -6.7841 -6.1477
[torch.FloatTensor of size 1x7]

-------------
i = 20, current_train_loss = [ 0.41624764]
W.data = 
1.00000e-02 *
 -7.7951  5.4833  5.6389  5.1259  4.6044  3.8318  2.8063
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-02 *
  2.2716 -1.5263 -1.2110 -0.8595 -0.5889 -0.2272  0.2457
[torch.FloatTensor of size 1x7]

-------------
i = 40, current_train_loss = [ 0.41519922]
W.data = 
-0.1048  0.0816  0.0738  0.0608  0.0500  0.0351  0.0155
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-02 *
  0.8291 -1.2087 -0.6707 -0.2695  0.0040  0.3552  0.8145
[torch.FloatTensor of size 1x7]

-------------
i = 60, current_train_loss = [ 0.41462538]
W.data = 
-0.1170  0.1038  0.0852  0.0645  0.0486  0.0270 -0.0016
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-02 *
  0.4840 -1.0275 -0.5054 -0.1425  0.0971  0.4218  0.8605
[torch.FloatTensor of size 1x7]

-------------
i = 80, current_train_loss = [ 0.41419011]
W.data = 
-0.1254  0.1228  0.0944  0.0670  0.0467  0.0188 -0.0183
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-03 *
  3.7304 -8.8880 -4.2453 -1.1229  0.8995  3.8752  8.0646
[torch.FloatTensor of size 1x7]

-------------
i = 100, current_train_loss = [ 0.41385156]
W.data = 
-0.1322  0.1393  0.1022  0.0691  0.0451  0.0116 -0.0337
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-03 *
  3.1566 -7.7141 -3.6694 -1.0268  0.6516  3.3819  7.3930
[torch.FloatTensor of size 1x7]

-------------
i = 120, current_train_loss = [ 0.41358718]
W.data = 
-0.1380  0.1537  0.1091  0.0711  0.0441  0.0053 -0.0478
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-03 *
  2.7367 -6.6936 -3.1913 -0.9771  0.3959  2.9086  6.7620
[torch.FloatTensor of size 1x7]

-------------
i = 140, current_train_loss = [ 0.41337979]
W.data = 
-0.1431  0.1661  0.1150  0.0731  0.0436 -0.0000 -0.0608
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-03 *
  2.3856 -5.8009 -2.7770 -0.9401  0.1637  2.4848  6.1992
[torch.FloatTensor of size 1x7]

-------------
i = 160, current_train_loss = [ 0.41321632]
W.data = 
-0.1476  0.1769  0.1202  0.0749  0.0435 -0.0046 -0.0726
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-03 *
  2.0813 -5.0188 -2.4141 -0.9086 -0.0414  2.1110  5.7028
[torch.FloatTensor of size 1x7]

-------------
i = 180, current_train_loss = [ 0.41308677]
W.data = 
-0.1515  0.1862  0.1247  0.0767  0.0437 -0.0085 -0.0836
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-03 *
  1.8151 -4.3334 -2.0954 -0.8805 -0.2214  1.7824  5.2663
[torch.FloatTensor of size 1x7]

--- 0.15782642364501953 seconds ---
--- 0.002630440394083659 minutes ---
--- 4.384067323472765e-05 hours ---

plotting={'save_bulk_experiment': True, 'plotting': False}
lb_test=
