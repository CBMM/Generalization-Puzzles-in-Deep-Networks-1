/home/brando90/home_simulation_research/overparametrized_experiments/pytorch_experiments
SLURM_ARRAY_TASK_ID =  32
SLURM_JOBID =  9699827

--Degree_mdl=6 
--degrees=[3, 4, 5, 6, 7, 8] 
--SLURM_ARRAY_TASK_ID=32 

reg_lambda =  0
nb_iter =  800000
N_train=7, N_test=200
--->training SP mdl
nb =  800000
reg_lambda =  0
reg_type =  
reg_lambda=0
-------------
i = 0, current_train_loss = [ 0.42564547]
W.data = 

Columns 0 to 5 
-4.1988e-17  8.2479e-03  8.2479e-03  7.7896e-03  7.3314e-03  6.7841e-03

Columns 6 to 6 
 6.1477e-03
[torch.FloatTensor of size 1x7]

W.grad.data = 

Columns 0 to 5 
 4.1988e-16 -8.2479e-02 -8.2479e-02 -7.7896e-02 -7.3314e-02 -6.7841e-02

Columns 6 to 6 
-6.1477e-02
[torch.FloatTensor of size 1x7]

-------------
i = 80000, current_train_loss = [ 0.38830802]
W.data = 
-0.2229  1.8811 -4.4254 -1.7785  7.3261  5.8397 -8.4940
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0609 -1.4756  3.0806  3.7518 -6.6806 -6.6528  7.9323
[torch.FloatTensor of size 1x7]

-------------
i = 160000, current_train_loss = [ 0.37768847]
W.data = 
 -0.2565   2.6054  -5.4569  -5.3106  11.5306  10.7552 -13.7548
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0263 -0.4666 -0.1026  4.9213 -4.1504 -5.7451  5.5248
[torch.FloatTensor of size 1x7]

-------------
i = 240000, current_train_loss = [ 0.37011307]
W.data = 
 -0.2710   2.7707  -4.7042  -9.4873  14.3084  15.1469 -17.6583
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0159  0.0163 -1.5936  5.4314 -2.9555 -5.2867  4.3967
[torch.FloatTensor of size 1x7]

-------------
i = 320000, current_train_loss = [ 0.36330363]
W.data = 
 -0.2764   2.6753  -3.1275 -13.9428  16.4160  19.2705 -20.9136
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0089  0.2141 -2.2656  5.6618 -2.3752 -5.0515  3.8322
[torch.FloatTensor of size 1x7]

-------------
i = 400000, current_train_loss = [ 0.35675633]
W.data = 
 -0.2776   2.4574  -1.1697 -18.5049  18.1858  23.2583 -23.8501
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0012  0.3128 -2.5549  5.7412 -2.1045 -4.9330  3.5341
[torch.FloatTensor of size 1x7]

-------------
i = 480000, current_train_loss = [ 0.35037091]
W.data = 
 -0.2769   2.1881   0.9408 -23.0826  19.7968  27.1558 -26.6244
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0081  0.3599 -2.7120  5.7216 -1.9884 -4.8677  3.3678
[torch.FloatTensor of size 1x7]

-------------
i = 560000, current_train_loss = [ 0.34410602]
W.data = 
 -0.2752   1.8905   3.1313 -27.6602  21.3227  30.9882 -29.3007
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0015  0.3780 -2.7486  5.7114 -1.8898 -4.7647  3.3394
[torch.FloatTensor of size 1x7]

-------------
i = 640000, current_train_loss = [ 0.3379522]
W.data = 
 -0.2732   1.5831   5.3470 -32.2360  22.8486  34.7388 -31.9130
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
 -0.0102  0.3819 -2.7891  5.6215 -1.9032 -4.7658  3.2371
[torch.FloatTensor of size 1x7]

-------------
i = 720000, current_train_loss = [ 0.33190918]
W.data = 
 -0.2707   1.2658   7.5891 -36.8111  24.3745  38.4045 -34.4575
[torch.FloatTensor of size 1x7]

W.grad.data = 
1.00000e-04 *
  0.0034  0.4001 -2.7788  5.5445 -1.8990 -4.7102  3.2482
[torch.FloatTensor of size 1x7]

--- 610.9753420352936 seconds ---
--- 10.182922367254893 minutes ---
--- 0.16971537278758156 hours ---

plotting={'save_bulk_experiment': True, 'plotting': False}
lb_test=
